{% extends "admin/base_site.html" %}
{% load i18n %}

{% block content %}
<div id="content-main" class="audio-capture" data-socket-path="{{ socket_path }}">
  <div class="module">
    <h2>
      {% blocktrans with feature_name=feature.display %}
        {{ feature_name }} waveform monitor
      {% endblocktrans %}
    </h2>
    <p class="help">
      {% blocktrans %}
        This preview streams live audio data from the node microphone. Reload the page if
        the connection drops.
      {% endblocktrans %}
    </p>
    <div class="audio-capture__monitor" role="group" aria-label="{% trans "Live audio waveform" %}">
      <canvas
        id="audio-capture-waveform"
        class="audio-capture__canvas"
        height="240"
      >
        {% trans "Waveform preview requires canvas support." %}
      </canvas>
      <p id="audio-capture-status" class="audio-capture__status" aria-live="polite">
        {% trans "Connecting to node microphone…" %}
      </p>
    </div>
  </div>
</div>
{% endblock %}

{% block extrastyle %}
{{ block.super }}
<style>
  .audio-capture__monitor {
    background: #0b1721;
    padding: 1rem;
    border-radius: 6px;
    margin-bottom: 1.5rem;
  }

  .audio-capture__canvas {
    width: 100%;
    display: block;
    background: #030910;
    border-radius: 4px;
  }

  .audio-capture__status {
    margin: 0.75rem 0 0;
    color: #d1ecf1;
  }

  .audio-capture__status--error {
    color: #f8d7da;
  }
</style>
{% endblock %}

{% block extrahead %}
{{ block.super }}
<script>
  document.addEventListener("DOMContentLoaded", () => {
    const container = document.querySelector(".audio-capture");
    const canvas = document.getElementById("audio-capture-waveform");
    const statusEl = document.getElementById("audio-capture-status");

    if (!container || !canvas || !statusEl) {
      return;
    }

    const canvasCtx = canvas.getContext("2d");
    if (!canvasCtx) {
      statusEl.textContent = "{% trans "Waveform preview is not supported in this browser." %}";
      statusEl.classList.add("audio-capture__status--error");
      return;
    }

    function setStatus(message, level = "info") {
      statusEl.textContent = message;
      statusEl.classList.toggle("audio-capture__status--error", level === "error");
    }

    const socketPath = container.dataset.socketPath;
    if (!socketPath) {
      setStatus("{% trans "Audio capture socket path is unavailable." %}", "error");
      return;
    }

    let socket;
    let animationFrame;
    let latestPoints = [];

    function resizeCanvas() {
      const ratio = window.devicePixelRatio || 1;
      const width = canvas.clientWidth;
      const height = canvas.clientHeight || canvas.height;
      canvas.width = Math.floor(width * ratio);
      canvas.height = Math.floor(height * ratio);
      canvasCtx.setTransform(ratio, 0, 0, ratio, 0, 0);
      drawWaveform(latestPoints);
    }

    function clampValue(value) {
      if (Number.isNaN(value)) {
        return 0;
      }
      return Math.max(-1, Math.min(1, value));
    }

    function drawWaveform(points) {
      const width = canvas.clientWidth;
      const height = canvas.clientHeight;
      canvasCtx.clearRect(0, 0, width, height);
      canvasCtx.fillStyle = "#030910";
      canvasCtx.fillRect(0, 0, width, height);
      if (!Array.isArray(points) || points.length === 0) {
        return;
      }
      canvasCtx.lineWidth = 2;
      canvasCtx.strokeStyle = "#4db6ff";
      canvasCtx.beginPath();
      const step = width / points.length;
      let x = 0;
      points.forEach((raw, index) => {
        const value = clampValue(Number(raw));
        const y = height / 2 - (value * height) / 2;
        if (index === 0) {
          canvasCtx.moveTo(x, y);
        } else {
          canvasCtx.lineTo(x, y);
        }
        x += step;
      });
      canvasCtx.lineTo(width, height / 2);
      canvasCtx.stroke();
    }

    function scheduleDraw(points) {
      latestPoints = points;
      if (animationFrame) {
        cancelAnimationFrame(animationFrame);
      }
      animationFrame = requestAnimationFrame(() => drawWaveform(latestPoints));
    }

    function handleMessage(event) {
      let payload;
      try {
        payload = JSON.parse(event.data);
      } catch (error) {
        console.error(error);
        return;
      }
      if (!payload || typeof payload !== "object") {
        return;
      }
      if (payload.type === "waveform" && Array.isArray(payload.points)) {
        scheduleDraw(payload.points);
      } else if (payload.type === "status" && typeof payload.message === "string") {
        setStatus(payload.message);
      } else if (payload.type === "error" && typeof payload.message === "string") {
        setStatus(payload.message, "error");
      }
    }

    function connect() {
      const scheme = window.location.protocol === "https:" ? "wss" : "ws";
      const url = `${scheme}://${window.location.host}${socketPath}`;
      try {
        socket = new WebSocket(url);
      } catch (error) {
        console.error(error);
        setStatus("{% trans "Unable to open WebSocket connection." %}", "error");
        return;
      }
      socket.addEventListener("open", () => {
        setStatus("{% trans "Connected. Waiting for audio samples…" %}");
      });
      socket.addEventListener("message", handleMessage);
      socket.addEventListener("close", (event) => {
        if (event.code === 1000) {
          setStatus("{% trans "Audio preview finished." %}");
        } else {
          setStatus("{% trans "Connection closed unexpectedly. Reload to retry." %}", "error");
        }
      });
      socket.addEventListener("error", () => {
        setStatus("{% trans "WebSocket error. Check node logs for details." %}", "error");
      });
    }

    window.addEventListener("beforeunload", () => {
      if (animationFrame) {
        cancelAnimationFrame(animationFrame);
      }
      if (socket && socket.readyState === WebSocket.OPEN) {
        socket.close();
      }
    });

    window.addEventListener("resize", resizeCanvas);

    resizeCanvas();
    connect();
  });
</script>
{% endblock %}
